{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>Ensino Einstein</font>\n",
    "## <font color='black'>Ciência de Dados e Informática para a Área da Saúde</font>\n",
    ">### <font color='gray'>Data Science 3b : Risco de desenvolvimento de Diabetes</font>\n",
    ">##### <font color='gray'>professor Rodrigo Signorini</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url = 'images/DataSciene_Process_01.png', width = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url = 'images/DataSciene_Process_02.png', width = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(url = 'images/DataSciene_Process_03.png', width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do Problema de Negócio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar um modelo preditivo para prever o risco de uma pessoa desenvolver ou não diabetes. A métrica a ser utilizada para avaliação do modelo será definida conforme o entendimento sobre o problema for se desenvolvendo. Para tanto, será usado um *dataset* onde cada registro informa se o paciente desenvolveu ou não diabetes. Esse *dataset* possui 768 registros e 9 atributos, onde oito são variáveis preditoras (**_features_** - de 1 a 8) e uma é a variável a ser predita (**_label_** - 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenção de conhecimento sobre o assunto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Diabetes Mellitus_**, ou simplesmente diabetes, é um grupo de doenças metabólicas em que se verificam níveis elevados de glicose no sangue durante um longo intervalo de tempo. Os sintomas da elevada quantidade de glicose incluem necessidade frequente de urinar e aumento da sede (polidipsia) e da fome (polifagia). Quando não é tratada, a diabetes pode causar várias complicações. Entre as complicações agudas estão a cetoacidose (quando o corpo produz ácidos sanguíneos - cetonas - em excesso e não há insulina suficiente no corpo), coma hiperosmolar hiperglicémico (aumento do açúcar no sangue resultando em alta osmolaridade sem cetoacidose significativa) ou morte. Entre as complicações a longo prazo estão doenças cardiovasculares, acidentes vasculares cerebrais, doença renal crónica, úlceras no pé e retinopatia diabética.\n",
    "\n",
    "A diabetes é o resultado quer da produção insuficiente de insulina pelo pâncreas, quer da resposta inadequada das células do corpo à insulina produzida. Existem três tipos principais de diabetes:\n",
    "\n",
    "- A **diabetes mellitus tipo 1** resulta da produção de quantidade insuficiente de insulina pelo pâncreas. Este tipo era anteriormente denominado \"diabetes insulino-dependente\". As causas são desconhecidas.\n",
    "- A **diabetes mellitus tipo 2** tem origem na resistência à insulina, uma condição em que as células do corpo não respondem à insulina de forma adequada. À medida que a doença avança, pode também desenvolver-se insuficiência na produção de insulina. Este tipo era anteriormente denominado \"diabetes não insulino-dependente\". A principal causa é peso excessivo e falta de exercício físico.\n",
    "- A diabetes gestacional é a condição em que uma mulher sem diabetes apresenta níveis elevados de glicose no sangue durante a gravidez.\n",
    "\n",
    "Tanto a prevenção como o tratamento da diabetes consistem em manter uma dieta saudável, praticar regularmente exercício físico, manter um peso normal e abster-se de fumar. Em pessoas com a doença, é importante controlar a pressão arterial e manter a higiene dos pés. A diabetes do tipo 1 deve ser tratada com injeções regulares de insulina. A diabetes do tipo 2 pode ser tratada com medicamentos por via oral como metformina e glibenclamida, com ou sem insulina. Tanto a insulina como alguns medicamentos por via oral podem causar baixos níveis de glicose no sangue. Em pessoas obesas com diabetes do tipo 2, a cirurgia de redução do estômago pode ser uma medida eficaz. A diabetes gestacional geralmente resolve-se por si própria após o nascimento do bebê. No entanto, se não for tratada durante a gravidez pode ser a causa de várias complicações para a mãe e para o bebê.\n",
    "\n",
    "Estima-se que em 2015 cerca de 415 milhões de pessoas em todo o mundo tivessem diabetes. Cerca de 90% dos casos eram diabetes do tipo 2, o que corresponde a 8,3% da população adulta. A doença afeta em igual proporção mulheres e homens. Em 2014, a tendência sugeria que a prevalência continuaria a aumentar. A diabetes aumenta pelo menos duas vezes o risco de morte prematura. Entre 2012 e 2015, a diabetes foi a causa de entre 1,5 e 5 milhões de mortes anuais. Estima-se que em 2014 o custo económico global da doença tenha sido de U$ 612 bilhões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = \"black\">Gastos do Brasil com diabetes podem dobrar na próxima década, diz estudo britânico</font>\n",
    "<font color = \"gray\">País deve enfrentar um dos maiores fardos do mundo com a doença, que avança globalmente; para pesquisadora, impostos e mudanças políticas são cruciais para mudar isso.</font>\n",
    "\n",
    "_Por BBC - 23/03/2018_\n",
    "\n",
    "O avanço da diabetes no Brasil pode fazer com que os custos diretos e indiretos da doença dobrem até 2030, aponta pesquisa divulgada nesta sexta-feira pela universidade britânica King's College, em parceria com a Universidade de Gottingen (Alemanha).\n",
    "\n",
    "O estudo, que levantou dados de 180 países, levou em conta tanto despesas com o tratamento médico da diabetes quanto os impactos na atividade econômica – como a perda de produtividade de trabalhadores e as mortes prematuras decorrentes da doença e de males associados, como problemas cardíacos.\n",
    "\n",
    "Segundo o levantamento, os gastos do Brasil com a diabetes foram de US 57,7 bilhões em 2015.\n",
    "\n",
    "Até 2030, essas despesas podem subir para US 97 bilhões, segundo estimativas mais conservadoras, ou US 123 bilhões, no pior dos cenários avaliados pelo estudo europeu.\n",
    "\n",
    "É um dos custos mais altos do mundo em relação ao Produto Interno Bruto (PIB), diz à BBC Brasil Justine Davies, coautora do estudo e professora do Centro de Saúde Global do King's College.\n",
    "\n",
    "\"A doença tem sido vista como a próxima epidemia global, tem aumentado na maioria dos países e ninguém tem conseguido enfrentá-la\", acrescenta.\n",
    "\n",
    "Isso é grave porque a diabetes é uma importante causadora de cegueira, falência renal, problemas cardíacos, derrames e amputações, aponta a Organização Mundial da Saúde (OMS).\n",
    "\n",
    "A ameaça da diabetes ao Brasil é excepcionalmente grave, mas não é única no mundo: segundo Davies, nenhum dos países estudados tem conseguido resultados particularmente positivos no combate à doença.\n",
    "\n",
    "\"Nos EUA, provavelmente o país mais obeso do mundo, as taxas (de diabetes) estão se estabilizando – um dos poucos países onde isso aconteceu\", diz a pesquisadora. No entanto, o país enfrenta a perspectiva de gastar até US 680 bilhões em decorrência da doença em 2030.\n",
    "\n",
    "Na China, a projeção é de que os gastos relacionados à diabetes praticamente tripliquem na próxima década, passando de US 222 bilhões a US 631 bilhões.\n",
    "\n",
    "No mundo inteiro, a perspectiva é de que gaste-se US 2,5 trilhões direta e indiretamente com a diabetes, o dobro dos custos atuais. E a América Latina deve ficar com o maior fardo, se analisada a proporção em relação ao tamanho de seu PIB.\n",
    "\n",
    "Um dos fatores por trás disso, segundo Davies, é a estrutura populacional latino-americana: cresceu a prevalência de diabetes em uma população ainda relativamente jovem, em idade produtiva.\n",
    "\n",
    "No Brasil, estimativas apontam que entre 7% e 10% da população pode ser diabética – boa parte dela sem nem sequer ter sido diagnosticada. Segundo o estudo de Davies, essa porcentagem pode chegar a 14% em 2030, no pior dos cenários.\n",
    "\n",
    "Dados da OMS apontam que a prevalência global de diabetes entre adultos acima de 18 anos dobrou entre 1980 e 2014 no mundo – alcançando 422 milhões de pessoas. O maior crescimento tem sido registrado em países de renda baixa e média.\n",
    "\n",
    "Em 2015, os dados mais recentes disponíveis, 1,6 milhões de mortes foram diretamente causadas pela diabetes no globo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Descrição e informação sobre os atributos do dataset\n",
    "\n",
    "> 1. **_Pregnancies_** ( number of times pregnant > )\n",
    "> 2. **_OGTT_** ( two-hour 75-gram Oral Glucose To> lerance Test )\n",
    "> 3. **_DBP_** ( Diastolic Blood Pressure - mm Hg > ) \n",
    "> 4. **_Skin Thickness_** ( Triceps skin fold thic> kness - mm )\n",
    "> 5. **_Insulin_** ( two-hour serum insulin - mu U> /ml )\n",
    "> 6. **_BMI_** ( Body Mass Index - weight kg / (he> ight m)^2 )\n",
    "> 7. **_DPF_** ( Diabetes Pedigree Function )\n",
    "> 8. **_Age_** ( years )\n",
    "> 9. **_Class_** ( **0** = NO/FALSE or **1** = YES/POSITIVE )\n",
    "\n",
    "As 8 **_features_** foram escolhidas por terem sido notadas como fatores de risco significativos para diabetes tanto na população alvo deste *dataset* como em outras populações.\n",
    "\n",
    "O *dataset* em questão contém 768 registros, onde todos os pacientes são mulheres com pelo menos 21 anos de idade. A variável alvo (**_label_**) - denominada aqui **_Class_** - é binária e possui valores 0 (zero) ou 1 (um), sendo que 0 (zero) indica um teste negativo para diabetes e 1 (um) indica um teste positivo para diabetes. Existem 500 casos como classe 0 (zero) e 268 casos como classe 1 (um). A população para este estudo foi a população indígena de *Pima*, perto de *Phoenix*, *Arizona*. Essa população tem estado sob estudo contínuo desde 1965 pelo Instituto Nacional de Diabetes e Doenças Digestivas e Renais devido à sua alta taxa de incidência de diabetes.\n",
    "\n",
    "O *dataset* foi coletado pelo Instituto Nacional de Diabetes e Doenças Digestivas e Renais, que faz parte dos Institutos Nacionais de Saúde dos Estados Unidos, que por sua vez faz parte do Departamento de Saúde e Serviços Humanos. A missão do instituto é apoiar pesquisas, treinamento e comunicação com o público nas áreas de “diabetes e outras doenças endócrinas e metabólicas; doenças digestivas, distúrbios nutricionais e obesidade; e doenças renais, urológicas e hematológicas” para melhorar a saúde e a qualidade de vida das pessoas.\n",
    "\n",
    "###### OGTT ( two-hour, 75-gram Oral Glucose Tolerance Test  )\n",
    "Um teste de tolerância à glicose mede quão bem as células do seu corpo são capazes de absorver glicose (açúcar) depois que você consome uma quantidade específica de açúcar. Um teste oral de tolerância à glicose (OGTT) de duas horas e 75 gramas de glicose é usado para testar o diabetes. Um profissional de saúde fará uma coleta de sangue em jejum para testar primeiro o nível de glicose em jejum. Eles então pedem para você beber 8 onças de uma solução de glicose que contém 75 gramas de açúcar. Para um OGTT de 2 horas com ingestão de 75 g, um nível de glicose abaixo de 7,8 mmol / L (140 mg / dL) é normal, enquanto níveis mais altos indicam hiperglicemia. A glicose plasmática entre 7,8 mmol / L (140 mg / dL) e 11,1 mmol / L (200 mg / dL) indica \"tolerância à glicose diminuída\" (recentemente \"pré-diabetes\"), e níveis acima de 11,1 mmol / L em 2 horas confirmam diagnóstico de diabetes.\n",
    "\n",
    "##### Insulin ( two-hour serum insulin - mu U/ml )\n",
    "A insulina é um hormônio produzido e armazenado nas células beta do pâncreas. É secretada em resposta à glicose sanguínea elevada após uma refeição e é vital para o transporte e armazenamento de glicose, a principal fonte de energia do corpo. A insulina ajuda a transportar a glicose do sangue para dentro das células, ajudando a regular os níveis de glicose no sangue e tem um papel no metabolismo lipídico. Este teste mede a quantidade de insulina no sangue.\n",
    "Os níveis sanguíneos de insulina e glicose devem estar em equilíbrio. Depois de uma refeição, os carboidratos geralmente são decompostos em glicose e outros açúcares simples. Esses são absorvidos no sangue, fazendo com que o nível de glicose no sangue suba, o que por sua vez estimula o pâncreas a liberar insulina no sangue. À medida que a glicose se move nas células, o nível no sangue diminui e a liberação de insulina pelo pâncreas diminui.\n",
    "Se um indivíduo não é capaz de produzir insulina suficiente, ou se as células do corpo são resistentes aos seus efeitos (resistência à insulina), a glicose não pode atingir a maioria das células do corpo e as células morrem de fome. Enquanto isso, a glicemia aumenta para um nível não saudável. Isso pode causar distúrbios nos processos metabólicos normais que resultam em vários distúrbios e complicações, incluindo doença renal, doença cardiovascular e problemas neurológicos e visuais.\n",
    "Diabetes, um distúrbio associado a altos níveis de glicose e diminuição dos efeitos da insulina, pode ser uma condição de risco de vida. Pessoas com diabetes tipo 1 produzem muito pouca insulina e, portanto, necessitam de terapia de suplementação de insulina. O diabetes tipo 2 geralmente está relacionado à resistência à insulina, que aumenta com o tempo.\n",
    "Com a resistência à insulina, muitas das células do corpo são incapazes de responder aos efeitos da insulina, deixando a glicose no sangue. O corpo compensa produzindo quantidades adicionais do hormônio. Isso resulta em um alto nível de insulina no sangue (hiperinsulinemia) e superestimulação de alguns tecidos que permaneceram sensíveis à insulina. Com o tempo, esse processo causa um desequilíbrio na relação entre glicose e insulina e, sem tratamento, pode eventualmente causar complicações de saúde que afetam várias partes do corpo.\n",
    "\n",
    "##### DPF ( Diabetes Pedigree Function )\n",
    "Uma função que classifica a probabilidade de diabetes com base no histórico familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set(style = \"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo e Carregando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivo CSV usando Pandas\n",
    "arquivo = \"data/pima-data.csv\"\n",
    "colunas = [\"Pregnancies\", \"OGTT\", \"DBP\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DPF\", \"Age\", \"Class\"]\n",
    "dados = pd.read_csv(arquivo, names = colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as dimensões\n",
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 0) # mostrar todas as colunas\n",
    "pd.set_option('display.max_rows', 768)  # mostrar até 768 linhas para descrever todas as colunas linha a linha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='black'>Discovering</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar as primeiras linhas\n",
    "dados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando a existência de dados nulos\n",
    "dados.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os tipos de dados\n",
    "dados.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "dados.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>(!!!) considerações sobre as **_features_** através da observação do sumário estatístico (!!!)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analisando a distribuição das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição das classes\n",
    "dados.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ainda não definimos nossa métrica de avaliação para esse problema de negócio, não precisamos nos preocupar com o balanceamento das classes nesse momento. Com um melhor entendimento do cenário a ser analisado e das suas possibilidades, definiremos nossa métrica posteriormente e então decideremos se iremos proceder com a necessidade do balanceamento das classes ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analisando a distribuição de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('Pregnancies').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('OGTT').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('DBP').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('SkinThickness').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('Insulin').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('BMI').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('DPF').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.groupby('Age').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize = (16, 16))\n",
    "sns.distplot(dados.Pregnancies, bins = 20, fit = stats.norm, ax = ax[0, 0])\n",
    "sns.distplot(dados.OGTT, bins = 20, fit = stats.norm, ax = ax[0, 1])\n",
    "sns.distplot(dados.DBP, bins = 20, fit = stats.norm, ax = ax[1, 0])\n",
    "sns.distplot(dados.SkinThickness, bins = 20, fit = stats.norm, ax = ax[1, 1])\n",
    "sns.distplot(dados.Insulin, bins = 20, fit = stats.norm, ax = ax[2, 0])\n",
    "sns.distplot(dados.BMI, bins = 20, fit = stats.norm, ax = ax[2, 1])\n",
    "sns.distplot(dados.DPF, bins = 20, fit = stats.norm, ax = ax[3, 0])\n",
    "sns.distplot(dados.Age, bins = 20, fit = stats.norm, ax = ax[3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando a distribuição de cada **_feature_** através de um histograma, além da identificação de possíveis *outliers*, podemos notar que **_features_** como \"**_Pregnancies_**\", \"**_Insulin_**\", \"**_DPF_**\" e \"**_Age_**\" possuem características de distribuição exponencial e **_features_** como \"**_OGTT_**\", \"**_DBP_**\", \"**_SkinThikness_**\" e \"**_BMI_**\" possuem caracterísiticas de distribuição normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demais tipos de visualizações e possibilidades de entendimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'Pregnancies', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\n",
    "sns.regplot(x = 'Pregnancies', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'OGTT', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\n",
    "sns.regplot(x = 'OGTT', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'DBP', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\n",
    "sns.regplot(x = 'DBP', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'SkinThickness', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = \".\")\n",
    "sns.regplot(x = 'SkinThickness', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'Insulin', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\n",
    "sns.regplot(x = 'Insulin', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'BMI', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\n",
    "sns.regplot(x = 'BMI', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(x = 'DPF', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\n",
    "sns.regplot(x = 'DPF', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'Age', y = 'Class', data = dados, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\n",
    "sns.regplot(x = 'Age', y = 'Class', data = dados, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot (Seaborn)\n",
    "\n",
    "sns.pairplot(dados, hue = \"Class\", kind = \"reg\", markers = \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot (Seaborn)\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (16, 8))\n",
    "sns.boxplot(data = dados, orient = \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 8, ncols = 3, figsize = (20, 32))\n",
    "\n",
    "sns.boxplot(x = \"Pregnancies\", data = dados, dodge = False, orient = \"v\", ax = ax[0, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"Pregnancies\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[0, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"Pregnancies\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[0, 2])\n",
    "\n",
    "sns.boxplot(x = \"OGTT\", data = dados, dodge = False, orient = \"v\", ax = ax[1, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"OGTT\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[1, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"OGTT\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[1, 2])\n",
    "\n",
    "sns.boxplot(x = \"DBP\", data = dados, dodge = False, orient = \"v\", ax = ax[2, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"DBP\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[2, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"DBP\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[2, 2])\n",
    "\n",
    "sns.boxplot(x = \"SkinThickness\", data = dados, dodge = False, orient = \"v\", ax = ax[3, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"SkinThickness\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[3, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"SkinThickness\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[3, 2])\n",
    "\n",
    "sns.boxplot(x = \"Insulin\", data = dados, dodge = False, orient = \"v\", ax = ax[4, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"Insulin\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[4, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"Insulin\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[4, 2])\n",
    "\n",
    "sns.boxplot(x = \"BMI\", data = dados, dodge = False, orient = \"v\", ax = ax[5, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"BMI\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[5, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"BMI\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[5, 2])\n",
    "\n",
    "sns.boxplot(x = \"DPF\", data = dados, dodge = False, orient = \"v\", ax = ax[6, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"DPF\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[6, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"DPF\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[6, 2])\n",
    "\n",
    "sns.boxplot(x = \"Age\", data = dados, dodge = False, orient = \"v\", ax = ax[7, 0])\n",
    "sns.boxplot(x = \"Class\", y = \"Age\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[7, 1])\n",
    "sns.swarmplot(x = \"Class\", y = \"Age\", hue = \"Class\", data = dados, dodge = True, orient = \"v\", ax = ax[7, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Violin Plots\n",
    "\n",
    "O gráfico de violino é semelhante ao do *box plot*, exceto que ele também mostra a densidade de probabilidade dos dados em valores diferentes (no caso mais simples, isso poderia ser um histograma).\n",
    "\n",
    "É mais informativo, pois enquanto um *box plot* mostra apenas estatísticas resumidas, como médias/medianas e intervalos interquartis, o gráfico de violino mostra a distribuição completa dos dados. A diferença é particularmente útil quando a distribuição de dados é multimodal (mais de um pico). Neste caso, um gráfico de violino mostra claramente a presença de diferentes picos, sua posição e amplitude relativa. Essas informações não podem ser representadas com um box plot que apenas relata estatísticas de resumo. A parte interna de um gráfico de violino geralmente mostra a média (ou mediana) e o intervalo interquartílico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 4, ncols = 2, figsize = (16, 16))\n",
    "sns.violinplot(x = \"Pregnancies\", data = dados, ax = ax[0, 0], palette = \"Set3\")\n",
    "sns.violinplot(x = \"OGTT\", data = dados, ax = ax[0, 1], palette = \"Set3\")\n",
    "sns.violinplot (x = \"DBP\", data = dados, ax = ax[1, 0], palette = \"Set3\")\n",
    "sns.violinplot(x = \"SkinThickness\", data = dados, ax = ax[1, 1], palette = \"Set3\")\n",
    "sns.violinplot(x = \"Insulin\", data = dados, ax = ax[2, 0], palette = \"Set3\")\n",
    "sns.violinplot(x = \"BMI\", data = dados, ax = ax[2, 1], palette = \"Set3\")\n",
    "sns.violinplot(x = \"DPF\", data = dados, ax = ax[3, 0], palette = \"Set3\")\n",
    "sns.violinplot(x = \"Age\", data = dados, ax = ax[3, 1], palette = \"Set3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlação** é o relacionamento entre 2 variáveis. O método mais comum para calcular correlação é o método de *Pearson*. Correlação de -1 mostra uma correlação negativa, enquanto uma correlação de +1 mostra uma correlação positiva. Uma correlação igual a 0 mostra que não há relacionamento entre as variáveis.\n",
    "\n",
    "> *Alguns algoritmos, como **Regressão Logística**, podem apresentar problemas de performance se no dataset houver **_features_** altamente correlacionadas (colineares).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação de Pearson\n",
    "dados.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizando a Matriz de Correlação - Matplotlib e Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = dados.corr()\n",
    "k = 9\n",
    "cols = correlations.nlargest(k, \"Class\")[\"Class\"].index\n",
    "cm = np.corrcoef(dados[cols].values.T)\n",
    "sns.set(font_scale = 1.25)\n",
    "fig, ax = plt.subplots(figsize = (12, 6))\n",
    "ax = sns.heatmap(cm, vmin = -1, vmax = 1, cmap = \"Reds\", cbar = True, annot = True, square = False, \n",
    "                 fmt = \".3f\", annot_kws = {\"size\": 12}, yticklabels = cols.values, xticklabels = cols.values)\n",
    "\n",
    "# i, m = plt.ylim()\n",
    "# i += 0.9\n",
    "# m += -0.9\n",
    "# plt.ylim(i, m)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>(!!!) considerações sobre as **_features_** através da observação da correlação (!!!)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de possíveis dados inválidos\n",
    "Com base nas observações acima, notou-se a ausência de dados nulos, mas também a presença de valores **0**s (zeros) em todas as **_features_** exceto em \"**_DPF_**\" e \"**_Age_**\". Valores **0** (zero) na **_feature_** \"**_Pregnancies_**\" são totalmente aceitáveis, partindo do princípio de que certas mulheres nunca engravidaram e que não há nenhuma restrição a esse grupo estar contido no *dataset*, mas valores **0** (zero) nas **_features_** \"**_OGTT_**\", \"**_DBP_**\", \"**_SkinThicness_**\", \"**_Insulin_**\" e \"**_BMI_**\" aparentemente não fazem sentido, especialmente em \"**_DBP_**\". Vejamos algumas análises e inferências:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OGTT ( two-hour 75-gram Oral Glucose Tolerance Test )\n",
    "Como visto anteriormente, a glicose plasmática entre 7,8 mmol/L (140 mg/dL) e 11,1 mmol/L (200 mg/dL) indica \"tolerância à glicose diminuída\" (recentemente \"pré-diabetes\"), e níveis acima de 11,1 mmol/L confirmam diagnóstico de diabetes. Os valores considerados normais ficam entre 3.9 mmol/L (70/ mg/dl) e 7,8 mmol/L (140 mg/L), com pontos de atenção para determinados indivíduos que apresente resultados entre 6.1 mmol/L (110 mg/dl) e 7,8 mmol/L (140 mg/dL). Sendo assim, os **0**s (zeros) aqui também não são válidos. Segue ocorrências de casos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados[dados.OGTT == 0].shape[0])\n",
    "print(dados[dados.OGTT == 0].index.tolist())\n",
    "print(dados[dados.OGTT == 0].groupby('Class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DBP ( Diastolic Blood Pressure - mm Hg ) \n",
    "Com base em informações sobre a pressão arterial em adultos, qualquer pressão arterial diastólica abaixo de 60 é considerada hipotensão e precisa ser tratada com urgência. Assumindo que os indivíduos deste *dataset* (nesse caso mulheres a partir de 21 anos) parte não sofrem de hipotensão e parte sofrem de hipotensão mais estão sendo tratadas, os valores **0**s (zeros) são claramente inválidos. Sendo assim, vamos descobrir quantos são as ocorrências desses valores no atributo \"**_DBP_**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dados[dados.DBP == 0].shape[0])\n",
    "print(dados[dados.DBP == 0].index.tolist())\n",
    "print(dados[dados.DBP == 0].groupby('Class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skin Thickness ( Triceps skin fold thickness - mm )\n",
    "Para adultos saudáveis normais, a espessura das dobras cutâneas geralmente não é inferior a 10 mm, mesmo para as mulheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados[dados.SkinThickness == 0].shape[0])\n",
    "print(dados[dados.SkinThickness == 0].index.tolist())\n",
    "print(dados[dados.SkinThickness == 0].groupby('Class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insulin ( two-hour serum insulin - mu U/ml )\n",
    "Em alguns casos raros uma pessoa pode ter **0** (zero) insulina, mas quase certamente a mesma tem diabetes. Mas nesse *dataset*, **236** casos têm valor de insulina **0** (zero) e essão classificados como não tendo diabetes. Isso é um ponto de atenção e deve ser investigado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados[dados.Insulin == 0].shape[0])\n",
    "print(dados[dados.Insulin == 0].index.tolist())\n",
    "print(dados[dados.Insulin == 0].groupby('Class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BMI ( Body Mass Index - weight kg / (height m)^2 )\n",
    "Com base em informações, o *Índice de Massa Corporal (IMC)* entre os adultos varia de 18,5 a 30,0 ou superior. Supondo que nenhuma dessas mulheres seja extremamente baixa ou extremamente abaixo do peso, o *IMC* não deve ser próximo de **0** nem tão pouco **0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados[dados.BMI == 0].shape[0])\n",
    "print(dados[dados.BMI == 0].index.tolist())\n",
    "print(dados[dados.BMI == 0].groupby('Class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"**_SkinThickness_**\" e \"**_Insulin_**\" têm um grande número de casos com valores **0**s (zeros). \"**_OGTT_**\", \"**_DBP_**\" e \"**_BMI_**\" têm muito menos casos com valores **0**s (zeros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algumas maneiras de lidar com os possiveis dados inválidos:\n",
    "\n",
    "> - **Remoção dos dados inválidos**: Pode não funcionar com \"**_SkinThickness_**\" e \"**_Insulin_**\", pois ambas têm um grande número de dados inválidos. A remoção desses registros deixaria o *dataset* com muitos poucos dados em um conjunto de dados já pequeno. A aplicação dessa abordagem em \"**_OGTT_**\", \"**_DBP_**\" e \"**_BMI_**\" traria um impacto bem menor e é aceitável.\n",
    "\n",
    "\n",
    "> - **Substituição por valores médios**: Nem sempre efetivo e depende de uma análise bem criteriosa de cada **_feature_** candidata a receber essa abordagem para que se obtenha um resultado efetivo. Como exemplo, \"**_BMI_**\" se apresenta com uma certa correlação com a diabetes, portanto, colocar um valor médio para a mesma pode fornecer um sinal errado para o modelo ou reduzir o seu valor preditivo.\n",
    "\n",
    "\n",
    "> - **Não utilização da _feature_**: Aceitável no caso da \"**_SkinThickness_**\", pois apresenta **227** ocorrências e correlação quase nula com a diabetes, mas certamente uma decisão mais difícil no caso da \"**_Insulin_**\", pois a mesma apresenta 374 ocorrências e certa correlação com a diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constatação visual das features x class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregnancies ( number of times pregnant )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "Pregnancies_x = dados.groupby(\"Pregnancies\").Class.mean().reset_index()\n",
    "sns.barplot(Pregnancies_x.Pregnancies, Pregnancies_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo Pregnancies\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"Pregnancies\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"Pregnancies\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"Pregnancies x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OGTT ( two-hour 75-gram Oral Glucose Tolerance Test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "OGTT_x = dados.groupby(\"OGTT\").Class.mean().reset_index()\n",
    "sns.barplot(OGTT_x.OGTT, OGTT_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo OGTT\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"OGTT\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"OGTT\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"OGTT x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DBP ( Diastolic Blood Pressure - mm Hg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "DBP_x = dados.groupby(\"DBP\").Class.mean().reset_index()\n",
    "sns.barplot(DBP_x.DBP, DBP_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo DBP\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"DBP\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"DBP\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"DBP x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SkinThickness ( Triceps skin fold thickness - mm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "SkinThickness_x = dados.groupby(\"SkinThickness\").Class.mean().reset_index()\n",
    "sns.barplot(SkinThickness_x.SkinThickness, SkinThickness_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo SkinThikness\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"SkinThickness\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"SkinThickness\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"SkinThickness x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observação*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insulin ( two-hour serum insulin - mu U/ml )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "Insulin_x = dados.groupby(\"Insulin\").Class.mean().reset_index()\n",
    "sns.barplot(Insulin_x.Insulin, Insulin_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo Insulin\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"Insulin\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"Insulin\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"Insulin x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observação*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BMI ( Body Mass Index - weight kg / (height m)^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "BMI_x = dados.groupby(\"BMI\").Class.mean().reset_index()\n",
    "sns.barplot(BMI_x.BMI, BMI_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo BMI\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"BMI\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"BMI\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"BMI x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observação*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DPF ( Diabetes Pedigree Function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "DPF_x = dados.groupby(\"DPF\").Class.mean().reset_index()\n",
    "sns.barplot(DPF_x.DPF, DPF_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo DPF\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"DPF\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"DPF\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"DPF x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observação*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Age ( years )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "Age_x = dados.groupby(\"Age\").Class.mean().reset_index()\n",
    "sns.barplot(Age_x.Age, Age_x.Class, color = \"purple\")\n",
    "plt.title(\"% de chance de ser diagnosticado com diabetes pelo atributo Age\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 4))\n",
    "sns.distplot(dados[dados.Class == 0][\"Age\"], color = \"blue\", kde = False, label = \"0 Class\")\n",
    "sns.distplot(dados[dados.Class == 1][\"Age\"], color = \"red\", kde = False, label = \"1 Class\")\n",
    "plt.legend()\n",
    "plt.title(\"Age x Número de mulheres x diabetes negativa (0) ou positiva (1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observações*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando as decisões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminando a **_feature_** \"**_SkinThickness_**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2del = [\"SkinThickness\"]\n",
    "dados = dados.drop(col2del, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>(!!!) considerações sobre a **_feature_** \"**_Insulin_**\" (!!!)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando **_Feature Engineering_** e reconstruindo a **_feature_** \"**_Insulin_**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mask : Replace values where the condition is True.\n",
    "# ne   : Not equal\n",
    "\n",
    "dados['Insulin'].mask(dados['Insulin'].ne(0), 1, inplace=True)\n",
    "\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava o DataFrame no disco como CSV\n",
    "file = 'data/diabetes_v01.csv'\n",
    "dados.to_csv(file, header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivo CSV usando Pandas\n",
    "\n",
    "file = 'data/diabetes_v01.csv'\n",
    "\n",
    "dados_2 = pd.DataFrame() # cria e inicializa o DataFrame\n",
    "\n",
    "dados_2 = pd.read_csv(file,     # arquivo a ser importado\n",
    "                     header = 0 # informa que a primeira linha da base de dados contém o título das colunas (index = 0) \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as dimensões\n",
    "dados_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 0) # mostrar todas as colunas\n",
    "pd.set_option('display.max_rows', 768)  # mostrar até 768 linhas para descrever todas as colunas linha a linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as primeiras linhas\n",
    "dados_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando a existência de dados nulos\n",
    "dados_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "dados_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "dados_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os Dados para Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitos algoritmos esperam receber os dados em um formato específico. Você deve preparar os dados de acordo com uma estrutura que seja adequada ao algoritmo que você irá utilizar, o que pode requerer **transformações** diferentes nos dados. Ainda, é possível que, em alguns casos, bons resultados possam ser obtidos sem aplicar nenhuma transformção, mas é uma boa prática criar diferentes transformações nos dados para que se realize testes em diferentes algoritmos de *Machine Learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por que usar transformação logarítmica em dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há duas razões para que transformações como esta sejam aplicadas aos dados: uma estatística e uma proporcional.\n",
    "\n",
    "> **1.** Se a distribuição de uma **_feature_** possui viés - possui uma das extremidades elevadas e uma cauda longa - medidas como correlação ou regressão podem ser bastante influenciadas. A aplicação da transformação logarítmica pode reduzir o efeito desse viés.\n",
    "\n",
    "> **2.** Alguns conceitos são melhor compreendidos quando os tratamos de maneira que possamos compará-los sobre uma ótica de proporcionalidade. Suponha duas empresas, \"**A**\" e \"**B**\". \"**A**\" possui um faturamento que passa de 1.000 para 3.000 (uma diferença de 3 mil, sendo uma razão de 3), a qual uma grande diferença (triplicou). \"**B**\" possui um faturamento que passou de 1.000.000 para 1.003.000 (uma diferença 3 mil, sendo uma razão de 1,003), a qual uma pequena diferença. Nesse caso, a transformação logarítmica nos dados de faturamento poderia ser utilizada para comparar o crescimento das empresas de forma justa, deixando a relação entre os dados mais clara.\n",
    "\n",
    "##### !!! Falta de simetria na distribuição pode reduzir a performance de alguns modelo de Machine Learning !!!\n",
    "\n",
    "Utilizando funcionalidades da biblioteca **_numpy_**, é possível aplicar uma transformação logarítimica aos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SKEWNESS\n",
    "A **_skewness_** (assimetria), em estatística, é o grau de distorção da curva simétrica de sino em uma distribuição de probabilidade. Se a curva for deslocada para a esquerda ou para a direita, é dito que ela está inclinada. A assimetria pode ser quantificada como uma representação da extensão em que uma determinada distribuição varia de uma distribuição normal. Em outras palavras, a **_skewness_** informa a quantidade e a direção desse desvio. O valor da **_skewness_** pode ser positivo ou negativo, ou mesmo indefinido. Se a **_skewness_** for **0** (zero), os dados são perfeitamente simétricos, embora seja bastante improvável em dados do mundo real. Como regra geral:\n",
    "\n",
    "> Se *skewness* for **menor que -1** ou **maior que 1**, a distribuição é altamente distorcida.\n",
    "\n",
    "> Se *skewness* estiver **entre -1 e -0,5** ou **entre 0,5 e 1**, a distribuição será moderadamente inclinada.\n",
    "\n",
    "> Se *skewness* estiver **entre -0,5 e 0,5**, a distribuição é aproximadamente simétrica.\n",
    "\n",
    "Valores positivos (+) indicam uma cauda à direita, enquanto valores negativos (-) indicam uma cauda à esquerda.\n",
    "\n",
    "##### KURTOSIS\n",
    "Assim como a **_skewness_** (assimetria), a **_kurtosis_** (curtose) é uma medida estatística usada para descrever a distribuição de probabilidade. Enquanto a **_skewness_** diferencia valores extremos em uma das caudas, a **_kurtosis_** mede valores extremos em qualquer uma delas. Distribuições com **_kurtosis_** grande exibem dados de cauda que excedem as caudas da distribuição normal (por exemplo, cinco ou mais desvios padrão da média). Distribuições com baixa **_kurtosis_** exibem dados de cauda que geralmente são menos extremos que as caudas da distribuição normal.\n",
    "Às vezes, a **_kurtosis_** é confundida com uma medida do pico de uma distribuição. No entanto, a **_kurtosis_** é uma medida do peso combinado das caudas de uma distribuição em relação ao centro da distribuição. Como já dito acima e reforçando, quando um conjunto de dados aproximadamente normais é representado graficamente por meio de um histograma, ele mostra um pico de sino e a maioria dos dados dentro de + ou - três desvios padrão da média. No entanto, quando por exemplo há alta **_kurtosis_**, as caudas se estendem além dos + ou - três desvios padrão da distribuição normal. Sendo assim, a **_kurtosis_** mede \"cauda\", não \"pico\".\n",
    "\n",
    "> Se *kurtosis* for **igual a 3**, indica uma distribuição normal.\n",
    "\n",
    "> Se *kurtosis* for **maior que 3**, indica uma distribuição mais alta (afunilada) do que a normal.\n",
    "\n",
    "> Se *kurtosis* for **menor que 3**, indica uma distribuição mais baixa (achatada) do que a normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verificando e comparando as features antes e após a transformação logarítmica (ainda com influência dos valores 0s)\n",
    "fig, axs = plt.subplots(nrows = 8, ncols = 2, figsize = (15, 25))\n",
    "columns = list(dados_2.columns)\n",
    "i = 0\n",
    "\n",
    "for col in columns:\n",
    "    # Calculando skewness, kurtosis e a transformação logarítmica\n",
    "    attribute = dados_2[col]\n",
    "    skew = attribute.skew()\n",
    "    kurt = attribute.kurt()\n",
    "    log_attribute = np.log1p(attribute)\n",
    "    log_skew = log_attribute.skew()\n",
    "    log_kurt = log_attribute.kurt()\n",
    "    \n",
    "    # Plotando gráficos\n",
    "    sns.distplot(attribute, bins = 40, fit = stats.norm, ax = axs[i, 0])\n",
    "    sns.distplot(log_attribute, bins = 40, fit = stats.norm, ax = axs[i, 1])\n",
    "    \n",
    "    # Configurando plotagens\n",
    "    attr_name = columns[i]\n",
    "    axs[i, 0].set_title(f'{attr_name}\\n Skew:{skew:.4f}, Kurt:{kurt:.4f}')\n",
    "    axs[i, 1].set_title(f'{attr_name} < Log transformation >\\n Skew:{log_skew:.4f}, Kurt:{log_kurt:.4f}')\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolando as *features* onde os valores *0*s (zeros) são válidos\n",
    "\n",
    "> **_Pregnacies_**, **_Insulin_** e **_Class_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2del = ['OGTT', 'DBP', 'Insulin', 'BMI', 'DPF', 'Age', 'Class']\n",
    "pregnancies = dados_2.drop(col2del, axis = 1)\n",
    "\n",
    "pregnancies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2del = ['Pregnancies', 'OGTT', 'DBP', 'BMI', 'DPF', 'Age', 'Class']\n",
    "insulin = dados_2.drop(col2del, axis = 1)\n",
    "\n",
    "insulin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col2del = ['Pregnancies', 'OGTT', 'DBP', 'Insulin', 'BMI', 'DPF', 'Age']\n",
    "target = dados_2.drop(col2del, axis = 1)\n",
    "\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2del = ['Pregnancies', 'Insulin', 'Class']\n",
    "attributes = dados_2.drop(col2del, axis = 1)\n",
    "\n",
    "attributes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = attributes.replace(0, np.nan)\n",
    "\n",
    "attributes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_3 = pd.DataFrame()\n",
    "dados_3 = attributes.copy()\n",
    "\n",
    "dados_3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_3['Pregnancies'] = pregnancies\n",
    "dados_3['Insulin'] = insulin\n",
    "dados_3['Class'] = target\n",
    "\n",
    "dados_3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_3.dropna(axis = 0, how = 'any', inplace = True)\n",
    "\n",
    "dados_3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição das classes do Dataset\n",
    "dados_3.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Após os procedimentos adotados acima, a proporção das classes ficou distrubuída da seguinte maneira:')\n",
    "print()\n",
    "print('%.4f' % ((249/(475+249))*100), '% de casos positivos (Classe 1)')\n",
    "print('%.4f' % ((475/(475+249))*100), '% de casos negativos (Classe 0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verificando e comparando as features antes e após a transformação logarítmica (sem a influência dos valores 0s)\n",
    "fig, axs = plt.subplots(nrows = 8, ncols = 2, figsize = (15, 25))\n",
    "columns = list(dados_3.columns)\n",
    "i = 0\n",
    "\n",
    "for col in columns:\n",
    "    # Calculando skewness, kurtosis e a transformação logarítmica\n",
    "    attribute = dados_3[col]\n",
    "    skew = attribute.skew()\n",
    "    kurt = attribute.kurt()\n",
    "    log_attribute = np.log1p(attribute)\n",
    "    log_skew = log_attribute.skew()\n",
    "    log_kurt = log_attribute.kurt()\n",
    "    \n",
    "    # Plotando gráficos\n",
    "    sns.distplot(attribute, bins = 40, fit = stats.norm, ax = axs[i, 0])\n",
    "    sns.distplot(log_attribute, bins = 40, fit = stats.norm, ax = axs[i, 1])\n",
    "    \n",
    "    # Configurando plotagens\n",
    "    attr_name = columns[i]\n",
    "    axs[i, 0].set_title(f'{attr_name}\\n Skew:{skew:.4f}, Kurt:{kurt:.4f}')\n",
    "    axs[i, 1].set_title(f'{attr_name} < Log transformation >\\n Skew:{log_skew:.4f}, Kurt:{log_kurt:.4f}')\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aplicando a transformação logarítmica\n",
    "array = dados_3.values\n",
    "\n",
    "# Separando o array para a transformação : \n",
    "X2log = array[:, 0:6]   # features para serem transformadas\n",
    "X_insulin = array[:, 6] # feature \"Insulin\"\n",
    "y = array[:, 7]         # \"Class\"\n",
    "\n",
    "# Gerando a nova escala (Log)\n",
    "dados_3_loged = np.log1p(X2log)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", X2log)\n",
    "print(\"\\nDados Log: \\n\\n\", dados_3_loged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_Scaling_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Scaling_** é uma das transformações mais comuns e utilizadas e significa colocar os dados em uma mesma escala, geralmente entre **0** e **1**. Muitos algoritmos de *Machine Learning* irão se beneficiar dessa transformação e produzir melhores resultados.\n",
    "\n",
    "> *Importantíssimo para o processo de otimização, assim como para algoritmos de Regressão e Redes Neurais e algoritmos que usam medidas de distância, como o KNN.*\n",
    "\n",
    "O *scikit-learn* possui uma função para essa transformação, chamada **MinMaxScaler()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling (entre 0 e 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Transformando os dados\n",
    "transformer = MinMaxScaler(feature_range = (0, 1))\n",
    "dados_3_rescaled = transformer.fit_transform(dados_3_loged)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", dados_3_loged)\n",
    "print(\"\\nDados MinMaxScaler: \\n\\n\", dados_3_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruindo o DataFrame\n",
    "dados_4 = pd.DataFrame()\n",
    "\n",
    "dados_4 = pd.DataFrame({'OGTT': dados_3_rescaled[:, 0], \n",
    "                        'DBP': dados_3_rescaled[:, 1], \n",
    "                        'BMI': dados_3_rescaled[:, 2], \n",
    "                        'DPF': dados_3_rescaled[:, 3], \n",
    "                        'Age': dados_3_rescaled[:, 4], \n",
    "                        'Pregnancies': dados_3_rescaled[:, 5], \n",
    "                        'Insulin': X_insulin,\n",
    "                        'Class': y})\n",
    "dados_4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot (Seaborn)\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (16, 8))\n",
    "sns.boxplot(data = dados_4, orient = \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação de Pearson\n",
    "dados_4.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = dados_4.corr()\n",
    "k = 8\n",
    "cols = correlations.nlargest(k, \"Class\")[\"Class\"].index\n",
    "cm = np.corrcoef(dados_4[cols].values.T)\n",
    "sns.set(font_scale = 1.25)\n",
    "fig, ax = plt.subplots(figsize = (16, 8))\n",
    "ax = sns.heatmap(cm, vmin = -1, vmax = 1, cmap = \"Reds\", cbar = True, annot = True, square = False, \n",
    "                 fmt = \".3f\", annot_kws = {\"size\": 14}, yticklabels = cols.values, xticklabels = cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo as *features* [X], o *label* [y] e o valor de *seed* para controlar a aleatoriedade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features [X] e label [y]\n",
    "\n",
    "array = dados_4.values\n",
    "\n",
    "X = array[:, 0:7]\n",
    "y = array[:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento da aleatoriedade para garantir que os mesmos dados sejam sempre reproduzidos da mesma maneira\n",
    "# Importante para garantir a justa comparação de performance entre os algoritmos de Machine Learning\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações sobre a \"multicolinearidade\"\n",
    "\n",
    "**Multicolinearidade** em regressão é uma condição que ocorre quando variáveis preditoras (**_features_**) estão correlacionadas entre si. A multicolinearidade forte é problemática porque pode aumentar a variância dos coeficientes de regressão, tornando-os instáveis e causamdo impactos na estimativa dos parâmetros. Podemos diagnosticar multicolinearidade por meio do **VIF** (*Variance Inflation Factor*), o qual mede o quanto a variância de um coeficiente de regressão estimado aumenta se seus preditores estão correlacionados. Há muita discussão sobre qual valor ideal de um **VIF** é justo para julgar se o mesmo é indicativo de problemas de multicolinearidade, mas geralmente um valor maior que dez (**VIF** > 10) indica um problema considerável de multicolinearidade forte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = dados_4.columns[0:7]\n",
    "\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando acima os valores dos **VIF**s de todas as **_features_**, podemos identificar os altos valores resultantes para \"**_OGTT_** e \"**_DBP_**, nos informando que essas duas **_features_** apresentam uma forte multicolinearidade. Utilizando-se de todo o conhecimento absorvido através das análises já efetuadas para uma segura tomada de decisão, obviamente que nossa ação será optar por eliminar a \"**_DBP_**\" no intuito de diminuir a multicolinearidade da importante \"**_OGTT_**\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas antes de eliminar a \"**_DBP_**\" do *dataset*, vamos observar se a utilização de um algoritmo de *Machine Learning* pode nos auxiliar ou mesmo comprovar nossa decisão através de uma **_Feature Selection_**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa de **_feature selection_** é onde selecionamos as *features* que serão melhores candidatas a serem preditoras. O **_feature selection_** nos ajuda a reduzir o **overfitting** (quando o algoritmo aprende demais com os dados de treino e performa mal nos dados de teste), reduzir a dimencionalidade e assim reduzir o tempo de processamento e aumentar a performance do modelo.\n",
    "\n",
    "As *features* presentes no seu *dataset* têm grande influência na performance e no resultado do seu modelo preditivo.\n",
    "\n",
    "> *Importantíssimo notar que tanto features irrelevantes como colineares geram um impacto negativo na performance do modelo.*\n",
    "\n",
    "O *scikit-learn* possui funções que automatizam o trabalho de extração e seleção de variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Método Ensemble para Seleção de Features (ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método **_ExtraTreesClassifier_** pode ser usado para avaliar a importância relativa de cada *feature* em relação à previsibilidade da variável resposta (**_label_**), retornando um *score* para cada uma das mesmas.\n",
    "\n",
    "Pelas características de aleatoriedade inerentes a esse método e da metodologia de como a mesma é tratada (*Mean Decrease in Impurity*, ou *MDI*), geralmente há uma redução na variabilidade do modelo, mas às custas de um aumento ligeiramente maior no viés (*bias*). Tendo em vista que em nosso processo há todo um conhecimento prévio sobre as características e a importância de cada *feature* para o problema de negócio, o uso desse método é de grande valia no auxílio ao julgamento e à tomada de decisão sobre quais *features* devemos manter ou não em nosso estudo.\n",
    "\n",
    "> Essas estimativas (transformadas em um *ranking* e cujos valores são positivos e somam **1**) são armazenadas em uma matriz e podem ser acessadas através do atributo *feature_importances_* (observar no código abaixo e estudar o mesmo através do respectivo *link* acima). Quanto maior o valor, mais importante é a contribuição da *feature* como preditora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTreesClassifier\n",
    "\n",
    "# Import dos Módulos\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Criação do Modelo - Feature Selection\n",
    "modelo = ExtraTreesClassifier(random_state=seed)\n",
    "modelo.fit(X, y)\n",
    "\n",
    "# Imprimindo os resultados\n",
    "importances = modelo.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"ranking das features:\")\n",
    "print()\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d - %s (%f)\" % (f + 1, indices[f], dados_4.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"ranking das features\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em linha com nossa análise prévia, o uso de um algoritmo de *machine learning* para uma **_feature selection_** também nos informa que \"**_DBP_**\" tem um grau de importância bem inferior quando comparado à \"**_OGTT_**\", ocupando a penúltima colocação no *ranking* gerado. Vamos eliminar a mesma sem mais nenhuma dúvida e observar o quanto essa eliminação reflete no grau de multicolinearidade da \"**_OGTT_**\" e também das demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_5 = pd.DataFrame()\n",
    "\n",
    "col2del = [\"DBP\"]\n",
    "dados_5 = dados_4.drop(col2del, axis = 1)\n",
    "\n",
    "dados_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features [X] e label [y]\n",
    "\n",
    "array = dados_5.values\n",
    "\n",
    "X = array[:, 0:6]\n",
    "y = array[:, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando o **VIF** novamente após a remoção da **_feature_** \"**_DBP_**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando VIF\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = dados_5.columns[0:6]\n",
    "\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o valor do **VIF**s da **_feature_** \"**_OGTT_**, nota-se que o valor foi reduzido de **16.5** para **10.7**, mas o mesmo ainda se encontra acima de **10.0**. Nota-se também uma redução no valor da \"**_BMI_** de **9.0** para **7.5** e da \"**_Pregnancies_**\" de **5.6** para **5.2**.\n",
    "\n",
    "O questionamento nesse ponto é: Eliminando-se a pouco representativa **_feature_** \"**_Insulin_**\" (correlação nula com a *target* \"**_Class_**\" e última colacada no *ranking* da **_Feature Selection_**), conseguiríamos reduzir ainda mais o valor do **VIF** da \"**_OGTT_**\" e torná-lo idealmente igual ou abaixo de **10.0**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_6 = pd.DataFrame()\n",
    "\n",
    "col2del = [\"Insulin\"]\n",
    "dados_6 = dados_5.drop(col2del, axis = 1)\n",
    "\n",
    "dados_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features [X] e label [y]\n",
    "\n",
    "array = dados_6.values\n",
    "\n",
    "X = array[:, 0:5]\n",
    "y = array[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando VIF\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = dados_6.columns[0:5]\n",
    "\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excelente! O valor do **VIF** da \"**_OGTT_**\" ficou em um nível aceitável - **10.1** - e ainda contribuiu para a redução da multicolinearidade das **_features_** \"**_DPF_**\" e \"**_Age_**\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há como como saber qual algoritmo vai funcionar melhor na construção de um modelo antes de o testarmos em um *dataset*. O ideal é testar alguns algoritmos e então escolher o que fornece melhor performance de acordo com o problema de negócio proposto. Vamos testar um conjunto de algoritmos de classificação (nas mesmas condições) e validarmos nossas conclusões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Models\n",
    "> LogisticRegression\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "##### Linear Discriminant Analysis\n",
    "> LinearDiscriminantAnalysis\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "\n",
    "##### Support Vector Machines\n",
    "> SVC\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "\n",
    "##### Stochastic Gradient Descent\n",
    "> SGDClassifier\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "##### Nearest Neighbors\n",
    "> KNeighborsClassifier\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "\n",
    "##### Naive Bayes\n",
    "> GaussianNB\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "##### Decision Trees\n",
    "> DecisionTreeClassifier\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "##### Ensemble methods\n",
    "\n",
    "> RandomForestClassifier\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "> AdaBoostClassifier\n",
    "> \n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "\n",
    "##### Neural network models (supervised)\n",
    "> MLPClassifier\n",
    ">\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção do Modelo Preditivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Cross Validation_** é uma das técnicas mais comuns para avaliação e seleção de modelos. A principal idéia é que cada observação em nosso conjunto de dados tenha a oportunidade de ser testada. O conjunto de dados é divido em **K** partes: uma parte é usada para a validação (subconjunto de teste) e as restantes partes (**K-1**) para o aprendizado (subconjunto de treino). Obtemos então o desempenho da aplicação da técnica através do cálculo da média aritmética das **K** estimativas dos subconjuntos de validação (teste). O principal benefício por trás dessa abordagem em comparação a uma simples e única divisão de dados de treino e teste (*Train/Test Split*) é reduzir o viés pessimista (*bias*) expondo o modelo à uma gama de possibilidades de cenários completos (restritos ao número predefinido do **K**) para treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "\n",
    "# Import dos módulos\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "num_folds = 10\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(n_splits = num_folds, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Definindo e Construindo os Scores\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "def accuracy(y_true, y_pred): return accuracy_score(y_true, y_pred)\n",
    "def precision(y_true, y_pred): return precision_score(y_true, y_pred)\n",
    "def recall(y_true, y_pred): return recall_score(y_true, y_pred)\n",
    "def f1(y_true, y_pred): return f1_score(y_true, y_pred)\n",
    "def balanced_accuracy(y_true, y_pred): return balanced_accuracy_score(y_true, y_pred)\n",
    "def roc_auc(y_true, y_pred): return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "scoring = {'tn' : make_scorer(tn), 'fp' : make_scorer(fp),\n",
    "           'fn' : make_scorer(fn), 'tp' : make_scorer(tp), \n",
    "           'accuracy' : make_scorer(accuracy), \n",
    "           'precision' : make_scorer(precision), \n",
    "           'recall' : make_scorer(recall), \n",
    "           'f1' : make_scorer(f1), \n",
    "           'balanced_accuracy' : make_scorer(balanced_accuracy), \n",
    "           'roc_auc' : make_scorer(roc_auc), \n",
    "          }\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Preparando a lista de algoritmos\n",
    "modelos = []\n",
    "modelos.append(('LogisticRegression', LogisticRegression(random_state = seed, max_iter=400)))\n",
    "modelos.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis())) # não possui o parâmetro \"random_state\"\n",
    "modelos.append(('SVC', SVC(random_state = seed)))\n",
    "modelos.append(('SGDClassifier', SGDClassifier(random_state = seed)))\n",
    "modelos.append(('KNeighborsClassifier', KNeighborsClassifier())) # não possui o parâmetro \"random_state\"\n",
    "modelos.append(('GaussianNB', GaussianNB())) # não possui o parâmetro \"random_state\"\n",
    "modelos.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state = seed)))\n",
    "modelos.append(('RandomForestClassifier', RandomForestClassifier(random_state = seed)))\n",
    "modelos.append(('AdaBoostClassifier', AdaBoostClassifier(random_state = seed)))\n",
    "modelos.append(('MLPClassifier', MLPClassifier(max_iter=600, random_state = seed)))\n",
    "\n",
    "# Avaliando cada modelo em um loop\n",
    "resultados = []\n",
    "nomes = []\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    cv_results_1 = cross_validate(modelo, X, y, scoring=scoring, cv=kfold)\n",
    "    cv_results_2 = cross_val_predict(modelo, X, y, cv=kfold)\n",
    "    print('+', '-'*len(nome), '+')\n",
    "    print('|', nome, '|')\n",
    "    print()\n",
    "    print('Métricas de Avaliação : Média de cada resultado obtido em cada iteração do Cross Validation')\n",
    "    print('> accuracy            : %0.4f (+/- 1std %0.4f)' % (np.mean(cv_results_1['test_accuracy']), np.std(cv_results_1['test_accuracy'])))\n",
    "    print('> precision           : %0.4f (+/- 1std %0.4f)' % (np.mean(cv_results_1['test_precision']), np.std(cv_results_1['test_precision'])))\n",
    "    print('> recall              : %0.4f (+/- 1std %0.4f)' % (np.mean(cv_results_1['test_recall']), np.std(cv_results_1['test_recall'])))\n",
    "    print('> f1                  : %0.4f (+/- 1std %0.4f)' % (np.mean(cv_results_1['test_f1']), np.std(cv_results_1['test_f1'])))\n",
    "    print('> balanced_accuracy   : %0.4f (+/- 1std %0.4f)' % (np.mean(cv_results_1['test_balanced_accuracy']), np.std(cv_results_1['test_balanced_accuracy'])))\n",
    "    print('> roc-auc             : %0.4f (+/- 1std %0.4f)' % (np.mean(cv_results_1['test_roc_auc']), np.std(cv_results_1['test_roc_auc'])))\n",
    "    print()\n",
    "    print('Matriz de Confusão    : Soma de cada resultado obtido em cada iteração do Cross Validate')\n",
    "    print('> TN                  : {:0.4f}'.format(np.sum(cv_results_1['test_tn'])))\n",
    "    print('> FP                  : {:0.4f}'.format(np.sum(cv_results_1['test_fp']))) \n",
    "    print('> FN                  : {:0.4f}'.format(np.sum(cv_results_1['test_fn']))) \n",
    "    print('> TP                  : {:0.4f}'.format(np.sum(cv_results_1['test_tp'])))\n",
    "    c_matrix = confusion_matrix(y, cv_results_2)\n",
    "    group_names = ['TN','FP','FN','TP']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in c_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in c_matrix.flatten()/np.sum(c_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    sns.heatmap(c_matrix, annot=labels, fmt='', cmap='Reds')\n",
    "    plt.show()\n",
    "    print('Métricas de Avaliação : A partir da Matriz de Confusão com a soma de cada resultado obtido em cada iteração do Cross Validate')\n",
    "    TN = np.sum(cv_results_1['test_tn'])\n",
    "    FP = np.sum(cv_results_1['test_fp'])\n",
    "    FN = np.sum(cv_results_1['test_fn'])\n",
    "    TP = np.sum(cv_results_1['test_tp'])\n",
    "    accuracy = (TN+TP)/(TN+FP+FN+TP)\n",
    "    print('> accuracy            : %0.4f' % accuracy)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    print('> precision           : %0.4f' % precision)\n",
    "    recall = (TP)/(TP+FN) # sensitivity, hit rate ou true positive rate (TPR)\n",
    "    print('> recall              : %0.4f' % recall)\n",
    "    f1 = (2*precision*recall)/(precision+recall)\n",
    "    print('> f1                  : %0.4f' % f1)\n",
    "    sensibility = (TP)/(TP+FN) # recall, hit rate ou true positive rate (TPR)\n",
    "    print('> sensibility         : %0.4f' % sensibility)\n",
    "    specificity = (TN)/(TN+FP) # selectivity ou true negative rate (TNR)\n",
    "    print('> specificity         : %0.4f' % specificity)\n",
    "    balanced_accuracy = (sensibility+specificity)/(2)\n",
    "    print('> balanced_accuracy   : %0.4f' % balanced_accuracy)\n",
    "    print()\n",
    "\n",
    "#     resultados.append(cv_results)\n",
    "#     nomes.append(nome)\n",
    "#     msg = \"%s: %f (%f)\" % (nome, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)\n",
    "#     print('Report : ')\n",
    "#     print(classification_report(y, cv_results))\n",
    "#     print('Accuracy Score :',accuracy_score(y, cv_results))\n",
    "#     print('roc_auc Score :',roc_auc_score(y, cv_results))\n",
    "\n",
    "\n",
    "# for nome, modelo in modelos:\n",
    "#     nomes.append(nome)\n",
    "#     previsoes_cv_auto = cross_val_predict(modelo, X, y, cv = kfold, n_jobs = -1)\n",
    "#     matrix = confusion_matrix(y, previsoes_cv_auto)\n",
    "#     print(nome)\n",
    "#     print('Confusion Matrix :')\n",
    "#     print(matrix)\n",
    "#     print()\n",
    "#     print('Accuracy Score :',accuracy_score(y, previsoes_cv_auto))\n",
    "#     print('roc_auc Score :',roc_auc_score(y, previsoes_cv_auto))\n",
    "#     print()\n",
    "#     print('Report : ')\n",
    "#     print(classification_report(y, previsoes_cv_auto))\n",
    "#     print()\n",
    "\n",
    "# # Boxplot para comparar os algoritmos\n",
    "# fig = plt.figure()\n",
    "# fig.suptitle('Comparação de Algoritmos de Classificação')\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.boxplot(resultados)\n",
    "# ax.set_xticklabels(nomes)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando os resultados acima, qual mais se adequa às necessidades do seu problema de negócio?\n",
    "\n",
    "> modelo  : ?\n",
    ">\n",
    "> métrica : ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização do Modelo - Ajuste de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetros e hiperparâmetros são duas partes fundamentais de um algoritmo de *Machine Learning*:\n",
    "> **Parâmetros** são ajustados diretamente durante o processo de aprendizado e influenciam diretamente a performance do algoritmo. Os coeficientes de uma regressão linear, os pesos de uma rede neural, as fronteiras das vizinhanças no *kNN*, todos esses são parâmetros que se ajustam durante o treinamento de um modelo.\n",
    "\n",
    "> **Hiperparâmetros** são definidos previamente ao processo de treinamento. Eles representam características mais construtivas, como a métrica de avaliação, o número de neurônios de uma rede neural (ou camadas), o número de vizinhos do *kNN* e tantos outros. Os hiperparâmetros são muito importantes para a performance de um modelo e caso escolhidos sem nenhum critério podem torná-lo inútil ou muito longe do ótimo.\n",
    "\n",
    "Usando métodos de otimização conjuntamente com o **_Cross Validation_** podemos ajustar a performance do modelo através de um \"**_tuning_**\" (ajuste fino) desses hiperparâmetros de acordo com a métrica de avaliação escolhida.\n",
    "\n",
    "> É importantíssimo encontrar a melhor combinação entre os hiperparâmetros em cada algoritmo de *Machine Learning* e esse processo também é chamado de **otimização de hiperparâmetros**.\n",
    "\n",
    "O *scikit-learn* oferece alguns métodos para otimização automática de hiperparâmetros, sendo dois deles o **_Grid Search_** e o **_Random Search_**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **_GridSearchCV_** é um algoritmo de busca em grade que recebe um conjunto previamente determinado de valores de um ou mais hiperparâmetros e testa todas as combinações possíveis. Ao final dos testes, o algoritmo informa qual é a melhor combinação dos valores dos hiperparâmetros que satisfaça a métrica de avaliação determinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_grid = {'var_smoothing': [1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, \n",
    "                                  1e-09, \n",
    "                                  1e-08, 1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01]}\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = GaussianNB()\n",
    "\n",
    "# Criando o grid\n",
    "grid = GridSearchCV(estimator = modelo, param_grid = valores_grid, scoring = 'f1', cv = kfold)\n",
    "# Treinando o modelo\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Score:\", grid.scorer_, \": %.4f\" % (grid.best_score_ * 100), \"%\")\n",
    "print()\n",
    "print(\"Melhor configuração dos Hiperparâmetros:\", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_opt = GaussianNB(priors=None, var_smoothing=1e-17)\n",
    "\n",
    "# Treinamento do modelo otimizado em todo o dataset\n",
    "modelo_opt.fit(X, y)\n",
    "\n",
    "# Fazendo as previsões e construindo a Matriz de Confusão\n",
    "y_pred_opt = modelo_opt.predict(X)\n",
    "c_matrix_opt = confusion_matrix(y, y_pred_opt)\n",
    "\n",
    "# Imprimindo a Confusion Matrix, a métrica f1 e Classification Report\n",
    "print('Matriz de Confusçao :')\n",
    "print(c_matrix_opt)\n",
    "print()\n",
    "print('f1 : %.4f' % f1_score(y, y_pred_opt))\n",
    "print()\n",
    "print('Classification Report : ')\n",
    "print(classification_report(y, y_pred_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_v01 = GaussianNB(priors=None, var_smoothing=1e-17)\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_v01.fit(X, y)\n",
    "\n",
    "# Salvando o modelo\n",
    "arquivo = \"model/modelo_v01.sav\"\n",
    "pickle.dump(modelo_opt, open(arquivo, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo\n",
    "modelo_v01 = pickle.load(open(arquivo, 'rb'))\n",
    "\n",
    "reg2predict = 0 # índice do registro do dataset para prever\n",
    "\n",
    "# Gerando a previsão\n",
    "print(modelo_v01.predict([X[reg2predict]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
